{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from BorderModel import BorderData, clean_df_subset\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dbhelper import pd_query\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "                select \n",
    "            m.date,\n",
    "            metric as waittime,\n",
    "            year,\n",
    "            month,\n",
    "            week,\n",
    "            dayofweek,\n",
    "            minofday,\n",
    "            w.temp_max,\n",
    "            w.temp_mean,\n",
    "            w.temp_min,\n",
    "            w.viz_max,\n",
    "            w.wind_max,\n",
    "            w.precip,\n",
    "            w.rain,\n",
    "            w.snow,\n",
    "            w.fog,\n",
    "            w.thunderstorm,\n",
    "            wp1.temp_max as temp_max_p1,\n",
    "            wp1.temp_mean as temp_mean_p1,\n",
    "            wp1.temp_min as temp_min_p1,\n",
    "            wp1.precip as precip_p1,\n",
    "            wp1.rain as rain_p1,\n",
    "            wp1.snow as snow_p1,\n",
    "            wp1.thunderstorm as thunderstorm_p1,\n",
    "            wp2.temp_max as temp_max_p2,\n",
    "            wp2.temp_mean as temp_mean_p2,\n",
    "            wp2.temp_min as temp_min_p2,\n",
    "            wp2.precip as precip_p2,\n",
    "            wp2.rain as rain_p2,\n",
    "            wp2.snow as snow_p2,\n",
    "            wp2.thunderstorm as thunderstorm_p2,\n",
    "            wp3.temp_max as temp_max_p3,\n",
    "            wp3.temp_mean as temp_mean_p3,\n",
    "            wp3.temp_min as temp_min_p3,\n",
    "            wp3.precip as precip_p3,\n",
    "            wp3.rain as rain_p3,\n",
    "            wp3.snow as snow_p3,\n",
    "            wp3.thunderstorm as thunderstorm_p3,\n",
    "            wm1.temp_max as temp_max_m1,\n",
    "            wm1.temp_mean as temp_mean_m1,\n",
    "            wm1.temp_min as temp_min_m1,\n",
    "            wm1.precip as precip_m1,\n",
    "            wm1.rain as rain_m1,\n",
    "            wm1.snow as snow_m1,\n",
    "            wm1.thunderstorm as thunderstorm_m1,\n",
    "            wm2.temp_max as temp_max_m2,\n",
    "            wm2.temp_mean as temp_mean_m2,\n",
    "            wm2.temp_min as temp_min_m2,\n",
    "            wm2.precip as precip_m2,\n",
    "            wm2.rain as rain_m2,\n",
    "            wm2.snow as snow_m2,\n",
    "            wm2.thunderstorm as thunderstorm_m2,\n",
    "            s.event,\n",
    "            s_lead1.event as event_lead1,\n",
    "            s_lag1.event as event_lag1,\n",
    "            s_lead2.event as event_lead2,\n",
    "            s_lag2.event as event_lag2,\n",
    "            s_lead3.event as event_lead3,\n",
    "            s_lag3.event as event_lag3,\n",
    "            s_lead4.event as event_lead4,\n",
    "            s_lag4.event as event_lag4,\n",
    "            1 as sea,\n",
    "            1 as sea_lag1,\n",
    "            1 as sea_lead1,\n",
    "            1 as sea_lag2,\n",
    "            1 as sea_lead2,\n",
    "            1 as sea_lag3,\n",
    "            1 as sea_lead3,\n",
    "            1 as van,\n",
    "            1 as van_lag1,\n",
    "            1 as van_lead1,\n",
    "            1 as van_lag2,\n",
    "            1 as van_lead2,\n",
    "            1 as van_lag3,\n",
    "            1 as van_lead3\n",
    "        from mungedata m\n",
    "        join datefeatures d on m.date = d.date\n",
    "        left join publicholiday h on m.date::timestamp::date = h.date\n",
    "        left join weather w on m.date::timestamp::date = w.date\n",
    "        left join weather wp1 on m.date::timestamp::date = wp1.date - interval '1 day'\n",
    "        left join weather wp2 on m.date::timestamp::date = wp2.date - interval '2 day'\n",
    "        left join weather wp3 on m.date::timestamp::date = wp3.date - interval '3 day'\n",
    "        left join weather wm1 on m.date::timestamp::date = wm1.date + interval '1 day'\n",
    "        left join weather wm2 on m.date::timestamp::date = wm2.date + interval '2 day'\n",
    "        left join specialdates s on m.date::timestamp::date = s.date\n",
    "        left join specialdates s_lead1 on m.date::timestamp::date = s_lead1.date - interval '1 day'\n",
    "        left join specialdates s_lag1 on m.date::timestamp::date = s_lag1.date + interval '1 day'\n",
    "        left join specialdates s_lead2 on m.date::timestamp::date = s_lead2.date - interval '2 day'\n",
    "        left join specialdates s_lag2 on m.date::timestamp::date = s_lag2.date + interval '2 day'\n",
    "        left join specialdates s_lead3 on m.date::timestamp::date = s_lead3.date - interval '3 day'\n",
    "        left join specialdates s_lag3 on m.date::timestamp::date = s_lag3.date + interval '3 day'\n",
    "        left join specialdates s_lead4 on m.date::timestamp::date = s_lead4.date - interval '4 day'\n",
    "        left join specialdates s_lag4 on m.date::timestamp::date = s_lag4.date + interval '4 day'\n",
    "        left join schoolcalendar sea on m.date::timestamp::date = sea.date_out and sea.district='seattle'\n",
    "        left join schoolcalendar sea_lag1 on m.date::timestamp::date = sea_lag1.date_out + interval '1 day' and sea_lag1.district='seattle'\n",
    "        left join schoolcalendar sea_lead1 on m.date::timestamp::date = sea_lead1.date_out - interval '1 day' and sea_lead1.district='seattle'\n",
    "        left join schoolcalendar sea_lag2 on m.date::timestamp::date = sea_lag2.date_out + interval '2 day' and sea_lag2.district='seattle'\n",
    "        left join schoolcalendar sea_lead2 on m.date::timestamp::date = sea_lead2.date_out - interval '2 day' and sea_lead2.district='seattle'\n",
    "        left join schoolcalendar sea_lag3 on m.date::timestamp::date = sea_lag3.date_out + interval '3 day' and sea_lag3.district='seattle'\n",
    "        left join schoolcalendar sea_lead3 on m.date::timestamp::date = sea_lead3.date_out - interval '3 day' and sea_lead3.district='seattle'\n",
    "        left join schoolcalendar van on m.date::timestamp::date = van.date_out and van.district='vancouver'\n",
    "        left join schoolcalendar van_lag1 on m.date::timestamp::date = van_lag1.date_out + interval '1 day' and van_lag1.district='vancouver'\n",
    "        left join schoolcalendar van_lead1 on m.date::timestamp::date = van_lead1.date_out - interval '1 day' and van_lead1.district='vancouver'\n",
    "        left join schoolcalendar van_lag2 on m.date::timestamp::date = van_lag2.date_out + interval '2 day' and van_lag2.district='vancouver'\n",
    "        left join schoolcalendar van_lead2 on m.date::timestamp::date = van_lead2.date_out - interval '2 day' and van_lead2.district='vancouver'\n",
    "        left join schoolcalendar van_lag3 on m.date::timestamp::date = van_lag3.date_out + interval '3 day' and van_lag3.district='vancouver'\n",
    "        left join schoolcalendar van_lead3 on m.date::timestamp::date = van_lead3.date_out - interval '3 day' and van_lead3.district='vancouver'\n",
    "        where\n",
    "            crossing_id = 1\n",
    "            and m.date >= '2008-1-1'\n",
    "            and munger_id = 2\n",
    "            and (minute = 0 or minute = 30)\n",
    "            and is_waittime = true\n",
    "        order by m.date;\n",
    "        '''\n",
    "\n",
    "df1 = pd_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB:  0.88141701299\n",
      "Best score:  0.3344216369\n",
      "** MSE for last cv fold **\n",
      "Baseline :  96.7590735774\n",
      "Model    :  108.767377782\n",
      "** R^2 for last cv fold **\n",
      "Baseline :  0.14722281598\n",
      "Model    :  0.04138873277\n",
      "** Explained variance for last cv fold **\n",
      "Baseline :  0.304333505904\n",
      "Model    :  0.252355202825\n"
     ]
    }
   ],
   "source": [
    "from BorderModel import BorderData\n",
    "data = BorderData(df1, categoricals=['event'])\n",
    "\n",
    "model = ExtraTreesRegressor(n_jobs=-1, n_estimators=16, bootstrap=True, oob_score=True)\n",
    "params = {}\n",
    "grid = GridSearchCV(model, params, cv=data.cv_train)\n",
    "grid.fit(data.X_train, data.y_train)\n",
    "\n",
    "data.predict(grid)\n",
    "data.print_metrics(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB:  0.88141701299\n",
      "Best score:  0.3344216369\n",
      "** MSE for last cv fold **\n",
      "Baseline :  96.7590735774\n",
      "Model    :  108.767377782\n",
      "Ensemble :  91.6035695925\n",
      "Weights  :  (1.5428443763424418, 2.2515941269625834)\n",
      "** R^2 for last cv fold **\n",
      "Baseline :  0.14722281598\n",
      "Model    :  0.04138873277\n",
      "Ensemble :  0.192660375559\n",
      "** Explained variance for last cv fold **\n",
      "Baseline :  0.304333505904\n",
      "Model    :  0.252355202825\n",
      "Ensemble :  0.340117932775\n"
     ]
    }
   ],
   "source": [
    "data.predict_ensemble()\n",
    "data.print_metrics(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dict matching event features to log feature_importance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fdict = { k: v for k, v in zip(data.X.columns.values, np.log(grid.best_estimator_.feature_importances_)) if 'event' in k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fimport = pd.DataFrame.from_dict(fdict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fimport.columns = ['importance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fimport['weight'] = fimport.importance.apply(lambda x: x + 9 if x > -8 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fimport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fimport1 = fimport[~pd.isnull(fimport.weight)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fimport1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a weight array aligned with feature matrix\n",
    "1. Sum all columns in feature matrix that match columns in fimport1\n",
    "2. Multiply sum with fimport 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2015, 1, 1, ..., 0.0, 0.0, 0.0],\n",
       "       [2015, 1, 1, ..., 0.0, 0.0, 0.0],\n",
       "       [2015, 1, 1, ..., 0.0, 0.0, 0.0],\n",
       "       ..., \n",
       "       [2015, 1, 1, ..., 0.0, 0.0, 0.0],\n",
       "       [2015, 1, 1, ..., 0.0, 0.0, 0.0],\n",
       "       [2015, 1, 1, ..., 0.0, 0.0, 0.0]], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.X_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

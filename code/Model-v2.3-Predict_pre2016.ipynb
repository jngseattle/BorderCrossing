{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict 1 week at a time for dates before 2016\n",
    "1. Train model for 2 years\n",
    "2. Predict 1 week via IncrementalModel\n",
    "3. Repeat starting with next week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from BorderModel import run_Incremental, harmonic_mean\n",
    "from BorderQuery import insert_predictions\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import datetime\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import copy\n",
    "import pdb\n",
    "from sklearn.metrics import r2_score\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_train_test(date_end, test_days=7, train_years=2):\n",
    "    '''\n",
    "    IN \n",
    "        date_end: datetime.date of last day to predict\n",
    "        duration: days to predict\n",
    "        train_years: number of years to train\n",
    "    '''\n",
    "    train_start = date_end - datetime.timedelta(test_days + 366 * train_years)\n",
    "    train_end = date_end - datetime.timedelta(test_days)\n",
    "    test_start = date_end - datetime.timedelta(test_days)\n",
    "    test_end = date_end\n",
    "    return train_start, train_end, test_start, test_end\n",
    "    \n",
    "def run_multiweek(model, munger_id, crossing_id, first, last, test_days):\n",
    "    prlist = {}\n",
    "    test_date = first\n",
    "    while test_date < last + datetime.timedelta(test_days):\n",
    "        cpu = random.randint(0, 31)\n",
    "        train_start, train_end, test_start, test_end = create_train_test(test_date, test_days=test_days)\n",
    "\n",
    "        prlist[str(test_date)] = rc[cpu].apply(run_Incremental, model, munger_id, crossing_id,  \n",
    "                                           train_start, train_end, \n",
    "                                           test_start, test_end)\n",
    "        \n",
    "        test_date += datetime.timedelta(test_days)\n",
    "        \n",
    "    return prlist\n",
    "\n",
    "def score_df(models):\n",
    "    predict = {date: model.score()['model'] for date, model in models.items()}\n",
    "    ensemble = {date: model.score()['ensemble'] for date, model in models.items()}\n",
    "    baseline = {date: model.score()['baseline'] for date, model in models.items()}\n",
    "    \n",
    "    df = pd.DataFrame([predict, ensemble, baseline]).T\n",
    "    df.columns = ['predict', 'ensemble', 'baseline']\n",
    "    df.index.name = 'date'\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    return df\n",
    "\n",
    "def plot_scores(df):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.plot(df.baseline, label='baseline')\n",
    "    plt.plot(df.predict, label='predict')\n",
    "    plt.plot(df.ensemble, label='ensemble')\n",
    "    plt.axhline(0, color='y')\n",
    "    plt.legend();\n",
    "    \n",
    "def results_df(trained_models):\n",
    "    predict = pd.Series().append([model.y_predict for key, model in trained_models.items()]).sort_index()\n",
    "    ensemble = pd.Series().append([model.ensemble() for key, model in trained_models.items()]).sort_index()\n",
    "    baseline = pd.Series().append([model.baseline() for key, model in trained_models.items()]).sort_index()\n",
    "    actual = pd.Series().append([model.actual for key, model in trained_models.items()]).sort_index()\n",
    "  \n",
    "    df = pd.DataFrame()\n",
    "    df['predict'] = predict\n",
    "    df['ensemble'] = ensemble\n",
    "    df['baseline'] = baseline\n",
    "    df['actual'] = actual\n",
    "    return df\n",
    "\n",
    "def print_r2(results):\n",
    "    actual = results.actual.dropna()\n",
    "    print 'Predict: ', r2_score(actual, results.predict[actual.index])\n",
    "    print 'Ensemble: ', r2_score(actual, results.ensemble[actual.index])\n",
    "    print 'Baseline: ', r2_score(actual, results.baseline[actual.index])\n",
    "    \n",
    "# def get_trained(pr, first, last, test_days, exclude):\n",
    "def get_trained(pr, exclude=[]):\n",
    "    trained = {}\n",
    "    for date in sorted(pr.keys()):\n",
    "        if date not in [str(ex) for ex in exclude]:\n",
    "#             if pr[date].ready():\n",
    "#                 trained[date] = pr[date].get()\n",
    "#                 print date, trained[date].score()\n",
    "#             else:\n",
    "#                 print date, 'not ready'\n",
    "            trained[date] = pr[date].get()\n",
    "            \n",
    "    return trained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing datetime on engine(s)\n",
      "importing run_Incremental from BorderModel on engine(s)\n",
      "importing select_features,select_mungedata_simple,select_mungedata from BorderQuery on engine(s)\n",
      "importing ExtraTreesRegressor from sklearn.ensemble on engine(s)\n",
      "importing GridSearchCV from sklearn.grid_search on engine(s)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ipyparallel import Client\n",
    "rc = Client()\n",
    "dview = rc[:]\n",
    "\n",
    "# set proper working directory on all clients\n",
    "cwd = os.getcwd()\n",
    "dview.map(os.chdir, [cwd] * 40)\n",
    "# print(dview.apply_sync(os.getcwd))\n",
    "\n",
    "with dview.sync_imports():\n",
    "    import datetime\n",
    "    from BorderModel import run_Incremental\n",
    "    from BorderQuery import select_features, select_mungedata_simple, select_mungedata\n",
    "    from sklearn.ensemble import ExtraTreesRegressor\n",
    "    from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peace Arch South"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ExtraTreesRegressor(n_jobs=-1, n_estimators=96)\n",
    "grid = GridSearchCV(model, {})\n",
    "\n",
    "pr = run_multiweek(grid, 3, 1, datetime.date(2015, 1, 1), datetime.date(2016, 1, 1), 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trained = get_trained(pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = results_df(trained)\n",
    "with open('/home/ubuntu/BorderCrossing/data/results_1_2015.pkl', 'w') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print_r2(results['2015-1-1':'2016-1-1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ExtraTreesRegressor(n_jobs=-1, n_estimators=96)\n",
    "grid = GridSearchCV(model, {})\n",
    "\n",
    "first = datetime.date(2014, 1, 1)\n",
    "last = datetime.date(2015, 1, 1)\n",
    "pr = run_multiweek(grid, 3, 1, first, last, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exclude = []\n",
    "trained = get_trained(pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = score_df(trained)\n",
    "plot_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = results_df(trained)\n",
    "with open('/home/ubuntu/BorderCrossing/data/results_1_2014.pkl', 'w') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print_r2(results['2014-1-1':'2015-1-1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pacific Highway South"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ExtraTreesRegressor(n_jobs=-1, n_estimators=96)\n",
    "grid = GridSearchCV(model, {})\n",
    "first = datetime.date(2015, 1, 1)\n",
    "last = datetime.date(2016, 1, 1)\n",
    "\n",
    "pr = run_multiweek(grid, 3, 5, first, last, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained = get_trained(pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = score_df(trained)\n",
    "plot_scores(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = results_df(trained)\n",
    "with open('/home/ubuntu/BorderCrossing/data/results_5_2015.pkl', 'w') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print_r2(results['2015-1-1':'2016-1-1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ExtraTreesRegressor(n_jobs=-1, n_estimators=96)\n",
    "grid = GridSearchCV(model, {})\n",
    "\n",
    "first = datetime.date(2014, 1, 1)\n",
    "last = datetime.date(2015, 1, 1)\n",
    "pr = run_multiweek(grid, 3, 5, first, last, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained = get_trained(pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = score_df(trained)\n",
    "plot_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = results_df(trained)\n",
    "with open('/home/ubuntu/BorderCrossing/data/results_5_2014.pkl', 'w') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print_r2(results['2014-1-1':'2015-1-1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ExtraTreesRegressor(n_jobs=-1, n_estimators=96)\n",
    "grid = GridSearchCV(model, {})\n",
    "\n",
    "first = datetime.date(2013, 1, 1)\n",
    "last = datetime.date(2014, 1, 1)\n",
    "pr = run_multiweek(grid, 3, 5, first, last, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trained = get_trained(pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = results_df(trained)\n",
    "with open('/home/ubuntu/BorderCrossing/data/results_5_2013.pkl', 'w') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print_r2(results['2013-1-1':'2014-1-1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ExtraTreesRegressor(n_jobs=-1, n_estimators=96)\n",
    "grid = GridSearchCV(model, {})\n",
    "\n",
    "first = datetime.date(2012, 1, 1)\n",
    "last = datetime.date(2013, 1, 1)\n",
    "pr = run_multiweek(grid, 3, 5, first, last, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained = get_trained(pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = results_df(trained)\n",
    "with open('/home/ubuntu/BorderCrossing/data/results_5_2012.pkl', 'w') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print_r2(results[str(first):str(last)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ExtraTreesRegressor(n_jobs=-1, n_estimators=96)\n",
    "grid = GridSearchCV(model, {})\n",
    "\n",
    "first = datetime.date(2011, 1, 1)\n",
    "last = datetime.date(2012, 1, 1)\n",
    "pr = run_multiweek(grid, 3, 5, first, last, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained = get_trained(pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = results_df(trained)\n",
    "with open('/home/ubuntu/BorderCrossing/data/results_5_2011.pkl', 'w') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print_r2(results[str(first):str(last)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peace Arch North\n",
    "### 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ExtraTreesRegressor(n_jobs=-1, n_estimators=96)\n",
    "grid = GridSearchCV(model, {})\n",
    "\n",
    "first = datetime.date(2015, 1, 1)\n",
    "last = datetime.date(2016, 1, 1)\n",
    "pr = run_multiweek(grid, 4, 2, first, last, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trained = get_trained(pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = score_df(trained)\n",
    "plot_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = results_df(trained)\n",
    "with open('/home/ubuntu/BorderCrossing/data/results_2_2015.pkl', 'w') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print_r2(results['2015-1-1':'2016-1-1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ExtraTreesRegressor(n_jobs=-1, n_estimators=96)\n",
    "grid = GridSearchCV(model, {})\n",
    "\n",
    "first = datetime.date(2014, 1, 1)\n",
    "last = datetime.date(2015, 1, 1)\n",
    "pr = run_multiweek(grid, 4, 2, first, last, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trained = get_trained(pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = score_df(trained)\n",
    "plot_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = results_df(trained)\n",
    "with open('/home/ubuntu/BorderCrossing/data/results_2_2014.pkl', 'w') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print_r2(results['2014-1-1':'2015-1-1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pacific Highway North\n",
    "### 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ExtraTreesRegressor(n_jobs=-1, n_estimators=96)\n",
    "grid = GridSearchCV(model, {})\n",
    "\n",
    "first = datetime.date(2015, 1, 1)\n",
    "last = datetime.date(2016, 1, 1)\n",
    "pr = run_multiweek(grid, 4, 6, first, last, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trained = get_trained(pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = score_df(trained)\n",
    "plot_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = results_df(trained)\n",
    "with open('/home/ubuntu/BorderCrossing/data/results_6_2015.pkl', 'w') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print_r2(results['2015-1-1':'2016-1-1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ExtraTreesRegressor(n_jobs=-1, n_estimators=96)\n",
    "grid = GridSearchCV(model, {})\n",
    "\n",
    "first = datetime.date(2014, 1, 1)\n",
    "last = datetime.date(2015, 1, 1)\n",
    "pr = run_multiweek(grid, 4, 6, first, last, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trained = get_trained(pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = score_df(trained)\n",
    "plot_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = results_df(trained)\n",
    "with open('/home/ubuntu/BorderCrossing/data/results_6_2014.pkl', 'w') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print_r2(results['2014-1-1':'2015-1-1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

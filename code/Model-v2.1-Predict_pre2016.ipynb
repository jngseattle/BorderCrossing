{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict 1 week at a time for dates before 2016\n",
    "1. Train model for 2 years\n",
    "2. Predict 1 week via IncrementalModel\n",
    "3. Repeat starting with next week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from BorderModel import run_Incremental, harmonic_mean\n",
    "from BorderQuery import insert_predictions\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import datetime\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import copy\n",
    "import pdb\n",
    "from sklearn.metrics import r2_score\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_train_test(date_end, test_days=7, train_years=2):\n",
    "    '''\n",
    "    IN \n",
    "        date_end: datetime.date of last day to predict\n",
    "        duration: days to predict\n",
    "        train_years: number of years to train\n",
    "    '''\n",
    "    train_start = date_end - datetime.timedelta(test_days + 366 * train_years)\n",
    "    train_end = date_end - datetime.timedelta(test_days)\n",
    "    test_start = date_end - datetime.timedelta(test_days)\n",
    "    test_end = date_end\n",
    "    return train_start, train_end, test_start, test_end\n",
    "    \n",
    "def run_multiweek(model, munger_id, crossing_id, first, last, test_days):\n",
    "    prlist = {}\n",
    "    test_date = first\n",
    "    while test_date < last:\n",
    "        cpu = random.randint(0, 31)\n",
    "        train_start, train_end, test_start, test_end = create_train_test(test_date, test_days=test_days)\n",
    "\n",
    "        prlist[str(test_date)] = rc[cpu].apply_async(run_Incremental, model, munger_id, crossing_id,  \n",
    "                                           train_start, train_end, \n",
    "                                           test_start, test_end)\n",
    "        \n",
    "        test_date += datetime.timedelta(test_days)\n",
    "        \n",
    "    return prlist\n",
    "\n",
    "def score_df(models):\n",
    "    predict = {date: model.score()['model'] for date, model in models.items()}\n",
    "    ensemble = {date: model.score()['ensemble'] for date, model in models.items()}\n",
    "    baseline = {date: model.score()['baseline'] for date, model in models.items()}\n",
    "    \n",
    "    df = pd.DataFrame([predict, ensemble, baseline]).T\n",
    "    df.columns = ['predict', 'ensemble', 'baseline']\n",
    "    df.index.name = 'date'\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    return df\n",
    "\n",
    "def plot_scores(df):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.plot(df.baseline, label='baseline')\n",
    "    plt.plot(df.predict, label='predict')\n",
    "    plt.plot(df.ensemble, label='ensemble')\n",
    "    plt.axhline(0, color='y')\n",
    "    plt.legend();\n",
    "    \n",
    "def results_df(models):\n",
    "    predict = pd.Series().append([model.y_predict for key, model in trained_1.items()]).sort_index()\n",
    "    ensemble = pd.Series().append([model.ensemble() for key, model in trained_1.items()]).sort_index()\n",
    "    baseline = pd.Series().append([model.baseline() for key, model in trained_1.items()]).sort_index()\n",
    "    actual = pd.Series().append([model.actual for key, model in trained_1.items()]).sort_index()\n",
    "  \n",
    "    df = pd.DataFrame()\n",
    "    df['predict'] = predict\n",
    "    df['ensemble'] = ensemble\n",
    "    df['baseline'] = baseline\n",
    "    df['actual'] = actual\n",
    "    return df\n",
    "\n",
    "def print_r2(results):\n",
    "    actual = results.actual.dropna()\n",
    "    print 'Predict: ', r2_score(actual, results.predict[actual.index])\n",
    "    print 'Ensemble: ', r2_score(actual, results.ensemble[actual.index])\n",
    "    print 'Baseline: ', r2_score(actual, results.baseline[actual.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing datetime on engine(s)\n",
      "importing run_Incremental from BorderModel on engine(s)\n",
      "importing select_features,select_mungedata_simple,select_mungedata from BorderQuery on engine(s)\n",
      "importing ExtraTreesRegressor from sklearn.ensemble on engine(s)\n",
      "importing GridSearchCV from sklearn.grid_search on engine(s)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ipyparallel import Client\n",
    "rc = Client()\n",
    "dview = rc[:]\n",
    "\n",
    "# set proper working directory on all clients\n",
    "cwd = os.getcwd()\n",
    "dview.map(os.chdir, [cwd] * 32)\n",
    "# print(dview.apply_sync(os.getcwd))\n",
    "\n",
    "with dview.sync_imports():\n",
    "    import datetime\n",
    "    from BorderModel import run_Incremental\n",
    "    from BorderQuery import select_features, select_mungedata_simple, select_mungedata\n",
    "    from sklearn.ensemble import ExtraTreesRegressor\n",
    "    from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peace Arch South"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ExtraTreesRegressor(n_jobs=-1, n_estimators=96)\n",
    "grid = GridSearchCV(model, {})\n",
    "\n",
    "pr = run_multiweek(grid, 3, 1, datetime.date(2015, 1, 1), datetime.date(2016, 1, 1), 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trained = {}\n",
    "first = datetime.date(2015, 1, 1)\n",
    "last = datetime.date(2016, 1, 1)\n",
    "test_days = 7\n",
    "test_date = first\n",
    "exclude = [datetime.date(2015, 2, 19)]\n",
    "while test_date < last:\n",
    "    if test_date not in exclude:\n",
    "        if pr[str(test_date)].ready():\n",
    "            trained[str(test_date)] = pr[str(test_date)].get(1)\n",
    "            print test_date, trained[str(test_date)].score()\n",
    "        else:\n",
    "            print  test_date, pr[str(test_date)].ready()\n",
    "\n",
    "    test_date += datetime.timedelta(test_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trained_1 = copy.deepcopy(trained)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = score_df(trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = results_df(trained)\n",
    "with open('/home/ubuntu/BorderCrossing/data/results_{0}_{1}.pkl', 'w') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_r2(results['2015-1-1':'2016-1-1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict:  0.391770485174\n",
      "Ensemble:  0.441411669676\n",
      "Baseline:  0.356917688188\n"
     ]
    }
   ],
   "source": [
    "print_r2(results['2015-1-1':'2016-1-1']) # old, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that baseline is a rolling 12 months, so not unexpected that baseline improves with week by week approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full2015 = run_Incremental(grid, 3, 1, '2013-1-1', '2015-1-1', '2015-1-1', '2016-1-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline': 0.1059067680212642,\n",
       " 'ensemble': 0.18871318906645274,\n",
       " 'model': 0.11903765655965948}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full2015.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pacific Highway South"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ExtraTreesRegressor(n_jobs=-1, n_estimators=96)\n",
    "grid = GridSearchCV(model, {})\n",
    "\n",
    "pr = run_multiweek(grid, 3, 5, datetime.date(2015, 1, 1), datetime.date(2016, 1, 1), 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01-01 {'model': 0.47442663738977786, 'ensemble': 0.50517844170980919, 'baseline': 0.53360635276911372}\n",
      "2015-01-08 {'model': 0.39309074740893124, 'ensemble': 0.43456830253917367, 'baseline': 0.42777892104205117}\n",
      "2015-01-15 {'model': -2.1356778917556496, 'ensemble': -2.2326721221699541, 'baseline': -2.5594198289083412}\n",
      "2015-01-22 {'model': 0.12515715332668176, 'ensemble': -0.11274671602146569, 'baseline': -0.71456686843956074}\n",
      "2015-01-29 {'model': -0.076635420776420826, 'ensemble': -0.46846544398769763, 'baseline': -1.8131967463785328}\n",
      "2015-02-05 {'model': 0.54517385665862328, 'ensemble': 0.35631724193852221, 'baseline': -1.2446526859107325}\n",
      "2015-02-12 {'model': 0.53979032357643542, 'ensemble': 0.64488156520051088, 'baseline': 0.56255811702560932}\n",
      "2015-02-26 {'model': 0.55647392504037918, 'ensemble': 0.63871064818947076, 'baseline': 0.37507249104058504}\n",
      "2015-03-05 {'model': 0.54205946570974994, 'ensemble': 0.40081046341057924, 'baseline': -0.49281888391150352}\n",
      "2015-03-12 {'model': 0.53805758304348883, 'ensemble': 0.38770162459874891, 'baseline': -0.60177025828530284}\n",
      "2015-03-19 {'model': 0.69789957975163464, 'ensemble': 0.74945356466012503, 'baseline': 0.59605078832362701}\n",
      "2015-03-26 {'model': 0.64141872302986858, 'ensemble': 0.63031217535970208, 'baseline': 0.45952992092539402}\n",
      "2015-04-02 {'model': 0.61491733635577916, 'ensemble': 0.59544643467252278, 'baseline': 0.44880066412729303}\n",
      "2015-04-09 {'model': 0.62774500274604916, 'ensemble': 0.60219654945908996, 'baseline': 0.43977370067121235}\n",
      "2015-04-16 {'model': 0.56652685857441332, 'ensemble': 0.44590425601890848, 'baseline': -0.186331269224979}\n",
      "2015-04-23 {'model': 0.59032198777358791, 'ensemble': 0.60311468701720761, 'baseline': 0.35701160644955166}\n",
      "2015-04-30 {'model': 0.66650078203316865, 'ensemble': 0.76778727075236386, 'baseline': 0.68102853197920732}\n",
      "2015-05-07 {'model': 0.64355855715908428, 'ensemble': 0.70385428995932986, 'baseline': 0.63342981933430842}\n",
      "2015-05-14 {'model': 0.57036612181200863, 'ensemble': 0.57928725849054863, 'baseline': 0.42625187177539714}\n",
      "2015-05-21 {'model': 0.41663702456434859, 'ensemble': 0.47682836765382075, 'baseline': 0.55700160454767045}\n",
      "2015-05-28 {'model': 0.18685534932001158, 'ensemble': 0.34497295496418834, 'baseline': 0.38812893482664057}\n",
      "2015-06-04 {'model': 0.65965823961333325, 'ensemble': 0.65922096723690005, 'baseline': 0.51796738921770036}\n",
      "2015-06-11 {'model': 0.61402226737162469, 'ensemble': 0.65008100247498812, 'baseline': 0.57391087981522948}\n",
      "2015-06-18 {'model': 0.37004255268724273, 'ensemble': 0.42582405199214335, 'baseline': 0.47892422247405686}\n",
      "2015-06-25 {'model': 0.68054359193844083, 'ensemble': 0.75267160084861962, 'baseline': 0.80283950153838735}\n",
      "2015-07-02 {'model': 0.64256373045116288, 'ensemble': 0.68558518859539841, 'baseline': 0.69524627935347283}\n",
      "2015-07-09 {'model': 0.33743615030581076, 'ensemble': 0.34100606274132805, 'baseline': 0.34846361845266449}\n",
      "2015-07-16 {'model': 0.70295109412801215, 'ensemble': 0.77485743910404392, 'baseline': 0.77705536919194196}\n",
      "2015-07-23 {'model': 0.61601405559327649, 'ensemble': 0.65519966235015736, 'baseline': 0.68892676082817417}\n",
      "2015-07-30 {'model': 0.47565134522724017, 'ensemble': 0.48816586672221929, 'baseline': 0.50040614127571958}\n",
      "2015-08-06 {'model': 0.65737588628433485, 'ensemble': 0.63229520816646612, 'baseline': 0.60060365618969036}\n",
      "2015-08-13 {'model': 0.55647824682035463, 'ensemble': 0.6596650276425311, 'baseline': 0.68457458172726604}\n",
      "2015-08-20 {'model': 0.71670777727539292, 'ensemble': 0.72951005087564846, 'baseline': 0.70549871247119977}\n",
      "2015-08-27 {'model': 0.69782699847568619, 'ensemble': 0.73195720732318015, 'baseline': 0.73944510131426289}\n",
      "2015-09-03 {'model': 0.057024301529705834, 'ensemble': 0.41470581009895369, 'baseline': 0.58897023139890115}\n",
      "2015-09-10 {'model': 0.43850624410394901, 'ensemble': 0.50119706332990555, 'baseline': 0.53410205481769812}\n",
      "2015-09-17 {'model': -0.88223061790377, 'ensemble': -0.99100190449110892, 'baseline': -1.2329337036946764}\n",
      "2015-09-24 {'model': 0.22892043793584749, 'ensemble': 0.017778174235348665, 'baseline': -0.42219869341386085}\n",
      "2015-10-01 {'model': 0.60348989040621182, 'ensemble': 0.45781957675989549, 'baseline': 0.044665544631873999}\n",
      "2015-10-08 {'model': 0.066139092561293467, 'ensemble': -0.32303962145384735, 'baseline': -1.2895856687474958}\n",
      "2015-10-22 {'model': 0.32105761955746082, 'ensemble': 0.1254425647031282, 'baseline': -0.59919857460913639}\n",
      "2015-10-29 {'model': 0.55007469918865315, 'ensemble': 0.41990290309596756, 'baseline': -0.11918982841754744}\n",
      "2015-11-05 {'model': -1.3472391153937293, 'ensemble': -2.4414916320269349, 'baseline': -5.045974237922529}\n",
      "2015-11-12 {'model': 0.31510174020613146, 'ensemble': 0.29099030242722446, 'baseline': -0.23388564435693238}\n",
      "2015-11-19 {'model': 0.023158054910677572, 'ensemble': 0.056603995942911545, 'baseline': -0.29832941280094571}\n",
      "2015-11-26 {'model': 0.66390754323719658, 'ensemble': 0.67938650099841413, 'baseline': 0.1504782175850804}\n",
      "2015-12-03 {'model': 0.39907313483273055, 'ensemble': 0.43488721035470035, 'baseline': 0.37569596586904996}\n",
      "2015-12-10 {'model': 0.34237024018154183, 'ensemble': 0.10701563577479078, 'baseline': -0.99569267471547662}\n",
      "2015-12-17 {'model': 0.31721208939810408, 'ensemble': -0.044756623759089065, 'baseline': -1.9033099269461342}\n",
      "2015-12-24 {'model': 0.35130011945480855, 'ensemble': 0.45941680718102251, 'baseline': 0.38832537395665756}\n",
      "2015-12-31 {'model': 0.12994701741676962, 'ensemble': 0.19720219749830603, 'baseline': 0.29750508672813014}\n"
     ]
    }
   ],
   "source": [
    "trained = {}\n",
    "first = datetime.date(2015, 1, 1)\n",
    "last = datetime.date(2016, 1, 1)\n",
    "test_days = 7\n",
    "test_date = first\n",
    "exclude = [datetime.date(2015, 10, 15), datetime.date(2015, 2, 19)]\n",
    "while test_date < last:\n",
    "    if test_date not in exclude:\n",
    "        if pr[str(test_date)].ready():\n",
    "            trained[str(test_date)] = pr[str(test_date)].get(1)\n",
    "            print test_date, trained[str(test_date)].score()\n",
    "        else:\n",
    "            print  test_date, pr[str(test_date)].ready()\n",
    "\n",
    "    test_date += datetime.timedelta(test_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_5 = copy.deepcopy(trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
